{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os \n",
    "os.environ['CUDA_VISIBLE_DEVICES'] = '2'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import esm\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.metrics import accuracy_score, roc_auc_score, f1_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "from torch.utils.data import DataLoader\n",
    "from tqdm import tqdm\n",
    "\n",
    "from datasets import PeptidePredictorDataset\n",
    "from models import PeptidePredictor\n",
    "\n",
    "max_seq_length = 12\n",
    "esm_model_pretrained, alphabet = esm.pretrained.esm2_t12_35M_UR50D()\n",
    "batch_converter = alphabet.get_batch_converter(truncation_seq_length=max_seq_length - 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda 1\n"
     ]
    }
   ],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(device, torch.cuda.device_count())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_stratification_key(length):\n",
    "    return str(length)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification splits: 75870 8431 9367\n",
      "Regression splits: 98537 10949 12166\n"
     ]
    }
   ],
   "source": [
    "regression_df = pd.read_csv(\"../../clean_data/merged_all.csv\", keep_default_na=False, na_values=[''])[['peptide', 'length', 'ap']]\n",
    "classification_df = pd.read_csv(\"../../clean_data/merged_all.csv\", keep_default_na=False, na_values=[''])[['peptide', 'length', 'is_assembled']]\n",
    "regression_df = regression_df.dropna(subset=['ap'])\n",
    "classification_df = classification_df.dropna(subset=['is_assembled'])\n",
    "\n",
    "classification_df['stratify_key'] = classification_df['length'].apply(get_stratification_key)\n",
    "regression_df['stratify_key'] = regression_df['length'].apply(get_stratification_key)\n",
    "\n",
    "def split_dataset(df, stratify_col, test_size=0.1, val_size=0.1, random_state=42):\n",
    "    train_val_df, test_df = train_test_split(\n",
    "        df, test_size=test_size, stratify=df[stratify_col], random_state=random_state\n",
    "    )\n",
    "    train_df, val_df = train_test_split(\n",
    "        train_val_df, test_size=val_size, stratify=train_val_df[stratify_col], random_state=random_state\n",
    "    )\n",
    "    return train_df, val_df, test_df\n",
    "\n",
    "train_cls, val_cls, test_cls = split_dataset(classification_df, 'stratify_key')\n",
    "train_reg, val_reg, test_reg = split_dataset(regression_df, 'stratify_key')\n",
    "\n",
    "print(\"Classification splits:\", len(train_cls), len(val_cls), len(test_cls))\n",
    "print(\"Regression splits:\", len(train_reg), len(val_reg), len(test_reg))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_cls_dataset = PeptidePredictorDataset(train_cls, task='classification')\n",
    "val_cls_dataset   = PeptidePredictorDataset(val_cls, task='classification')\n",
    "test_cls_dataset  = PeptidePredictorDataset(test_cls, task='classification')\n",
    "\n",
    "train_reg_dataset = PeptidePredictorDataset(train_reg, task='regression')\n",
    "val_reg_dataset   = PeptidePredictorDataset(val_reg, task='regression')\n",
    "test_reg_dataset  = PeptidePredictorDataset(test_reg, task='regression')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_and_pad(data, seq_length):\n",
    "    \"\"\"\n",
    "    Converts a list of (name, sequence) tuples into tokenized sequences using the batch converter,\n",
    "    and pads them to ensure a fixed length of max_seq_length tokens.\n",
    "    \"\"\"\n",
    "    _, _, tokens = batch_converter(data)\n",
    "\n",
    "    current_len = tokens.size(1)\n",
    "    if current_len < seq_length:\n",
    "        pad_length = seq_length - current_len\n",
    "        padding = torch.full((tokens.size(0), pad_length), alphabet.padding_idx, dtype=tokens.dtype)\n",
    "        tokens = torch.cat([tokens, padding], dim=1)\n",
    "    \n",
    "    return tokens\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def esm_collate_fn(batch):\n",
    "    \"\"\"\n",
    "    batch: list of tuples (sequence, target)\n",
    "    Returns:\n",
    "      - tokens: a tensor of shape (batch_size, seq_len) ready for the ESM model\n",
    "      - targets: a tensor of the corresponding targets\n",
    "    \"\"\"\n",
    "    data = [(f\"peptide_{i}\", seq) for i, (seq, _) in enumerate(batch)]\n",
    "\n",
    "    tokens = convert_and_pad(data, seq_length=max_seq_length)\n",
    "\n",
    "    targets = torch.tensor([target for _, target in batch])\n",
    "    return tokens, targets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 1024\n",
    "\n",
    "train_cls_loader = DataLoader(train_cls_dataset, batch_size=batch_size, shuffle=True, collate_fn=esm_collate_fn)\n",
    "val_cls_loader   = DataLoader(val_cls_dataset, batch_size=batch_size, shuffle=False, collate_fn=esm_collate_fn)\n",
    "test_cls_loader  = DataLoader(test_cls_dataset, batch_size=batch_size, shuffle=False, collate_fn=esm_collate_fn)\n",
    "\n",
    "train_reg_loader = DataLoader(train_reg_dataset, batch_size=batch_size, shuffle=True, collate_fn=esm_collate_fn)\n",
    "val_reg_loader   = DataLoader(val_reg_dataset, batch_size=batch_size, shuffle=False, collate_fn=esm_collate_fn)\n",
    "test_reg_loader  = DataLoader(test_reg_dataset, batch_size=batch_size, shuffle=False, collate_fn=esm_collate_fn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = PeptidePredictor(esm_model_pretrained, alphabet, hidden_dim=128, dropout=0.10)\n",
    "\n",
    "if torch.cuda.device_count() > 1:\n",
    "    print(f\"Using {torch.cuda.device_count()} GPUs\")\n",
    "    model = nn.DataParallel(model)\n",
    "model.to(device)\n",
    "\n",
    "model.freeze_encoder()\n",
    "optimizer = torch.optim.AdamW([\n",
    "    {\"params\": list(model.shared.parameters()) + \n",
    "               list(model.ap_head.parameters()) + \n",
    "               list(model.cls_head.parameters()), \"lr\": 1e-3}\n",
    "])\n",
    "criterion_cls = nn.BCEWithLogitsLoss()\n",
    "criterion_reg = nn.SmoothL1Loss(beta=0.5)\n",
    "\n",
    "num_epochs = 5\n",
    "alpha, beta = 1, 1\n",
    "\n",
    "reg_iterator = iter(train_reg_loader)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                      \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5 - Average Loss: 0.4069\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                      \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2/5 - Average Loss: 0.1737\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                      \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3/5 - Average Loss: 0.1520\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                      \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4/5 - Average Loss: 0.1403\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                       "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5/5 - Average Loss: 0.1328\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r"
     ]
    }
   ],
   "source": [
    "model.freeze_encoder()\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    epoch_loss = 0.0\n",
    "\n",
    "    pbar = tqdm(train_cls_loader, desc=f\"Epoch {epoch+1}/{num_epochs}\", leave=False)\n",
    "    \n",
    "    for cls_batch in pbar:\n",
    "        tokens_cls, cls_labels = cls_batch\n",
    "        #print(tokens_cls, cls_labels)\n",
    "        tokens_cls = tokens_cls.to(device)\n",
    "        cls_labels = cls_labels.to(device)\n",
    "        #print(tokens_cls, cls_labels)\n",
    "        ap_pred_cls, cls_pred = model(tokens_cls)\n",
    "        loss_cls = criterion_cls(cls_pred.squeeze(), cls_labels.float())\n",
    "        \n",
    "        try:\n",
    "            reg_batch = next(reg_iterator)\n",
    "        except StopIteration:\n",
    "            reg_iterator = iter(train_reg_loader)\n",
    "            reg_batch = next(reg_iterator)\n",
    "            \n",
    "        tokens_reg, reg_labels = reg_batch\n",
    "        tokens_reg = tokens_reg.to(device)\n",
    "        reg_labels = reg_labels.to(device)\n",
    "        \n",
    "        ap_pred_reg, _ = model(tokens_reg)\n",
    "        loss_reg = criterion_reg(ap_pred_reg.squeeze(), reg_labels.float())\n",
    "        \n",
    "        total_loss = alpha * loss_cls + beta * loss_reg\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        total_loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        epoch_loss += total_loss.item()\n",
    "        pbar.set_postfix(loss=total_loss.item())\n",
    "    \n",
    "    avg_loss = epoch_loss / len(train_cls_loader)\n",
    "    print(f\"Epoch {epoch+1}/{num_epochs} - Average Loss: {avg_loss:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                      \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/6 - Average Loss: 0.1258\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                       \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2/6 - Average Loss: 0.1181\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                       \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3/6 - Average Loss: 0.1109\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                       \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4/6 - Average Loss: 0.1062\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                       \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5/6 - Average Loss: 0.1005\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                       "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 6/6 - Average Loss: 0.0975\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r"
     ]
    }
   ],
   "source": [
    "#underlying_model = model.module if hasattr(model, \"module\") else model\n",
    "\n",
    "encoder_lr = 1e-5\n",
    "head_lr = 1e-3\n",
    "\n",
    "model.unfreeze_encoder()\n",
    "opt = torch.optim.Adam([\n",
    "    {\"params\": model.esm.parameters(), \"lr\": encoder_lr},\n",
    "    {\"params\": list(model.shared.parameters()) + \n",
    "               list(model.ap_head.parameters()) + \n",
    "               list(model.cls_head.parameters()), \"lr\": head_lr}\n",
    "])\n",
    "\n",
    "scheduler = optim.lr_scheduler.ExponentialLR(optimizer, gamma=0.75)\n",
    "\n",
    "num_epochs = 6\n",
    "for epoch in range(num_epochs):\n",
    "    epoch_loss = 0.0\n",
    "    pbar = tqdm(train_cls_loader, desc=f\"Epoch {epoch+1}/{num_epochs}\", leave=False)\n",
    "    for cls_batch in pbar:\n",
    "        tokens_cls, cls_labels = cls_batch\n",
    "        tokens_cls = tokens_cls.to(device)\n",
    "        cls_labels = cls_labels.to(device)\n",
    "        \n",
    "        ap_pred_cls, cls_pred = model(tokens_cls)\n",
    "        loss_cls = criterion_cls(cls_pred.squeeze(), cls_labels.float())\n",
    "        \n",
    "        try:\n",
    "            reg_batch = next(reg_iterator)\n",
    "        except StopIteration:\n",
    "            reg_iterator = iter(train_reg_loader)\n",
    "            reg_batch = next(reg_iterator)\n",
    "            \n",
    "        tokens_reg, reg_labels = reg_batch\n",
    "        tokens_reg = tokens_reg.to(device)\n",
    "        reg_labels = reg_labels.to(device)\n",
    "        \n",
    "        ap_pred_reg, _ = model(tokens_reg)\n",
    "        loss_reg = criterion_reg(ap_pred_reg.squeeze(), reg_labels.float())\n",
    "        \n",
    "        total_loss = alpha * loss_cls + beta * loss_reg\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        total_loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        epoch_loss += total_loss.item()\n",
    "        pbar.set_postfix(loss=total_loss.item())\n",
    "    \n",
    "    avg_loss = epoch_loss / len(train_cls_loader)\n",
    "    print(f\"Epoch {epoch+1}/{num_epochs} - Average Loss: {avg_loss:.4f}\")\n",
    "    \n",
    "    scheduler.step()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model saved to peptide_predictor.pt\n"
     ]
    }
   ],
   "source": [
    "model_to_save = model.module if hasattr(model, \"module\") else model\n",
    "torch.save(model_to_save.state_dict(), \"peptide_predictor.pt\")\n",
    "print(\"Model saved to peptide_predictor.pt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Metrics:\n",
      "Classification -> Accuracy: 0.9669, F1: 0.9754, AUC: 0.9954\n",
      "Regression     -> MSE: 0.0026, MAE: 0.0396, R²: 0.8858\n"
     ]
    }
   ],
   "source": [
    "def validate_model(model, cls_loader, reg_loader, device):\n",
    "    model.eval()\n",
    "    all_cls_preds = []\n",
    "    all_cls_labels = []\n",
    "    all_reg_preds = []\n",
    "    all_reg_labels = []\n",
    "    accuracy, f1, auc, mse, mae, r2 = float('nan'), float('nan'), float('nan'), float('nan'), float('nan'), float('nan')\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for tokens, targets in cls_loader:\n",
    "            tokens = tokens.to(device)\n",
    "            targets = targets.to(device)\n",
    "            _, cls_pred = model(tokens)\n",
    "            all_cls_preds.append(cls_pred.cpu())\n",
    "            all_cls_labels.append(targets.cpu())\n",
    "            \n",
    "        for tokens, targets in reg_loader:\n",
    "            tokens = tokens.to(device)\n",
    "            targets = targets.to(device)\n",
    "            ap_pred, _ = model(tokens)\n",
    "            all_reg_preds.append(ap_pred.cpu())\n",
    "            all_reg_labels.append(targets.cpu())\n",
    "    \n",
    "    if cls_loader:\n",
    "        all_cls_preds = torch.cat(all_cls_preds, dim=0).numpy().squeeze()\n",
    "        all_cls_labels = torch.cat(all_cls_labels, dim=0).numpy().squeeze()\n",
    "\n",
    "        cls_pred_labels = (all_cls_preds > 0.5).astype(int)\n",
    "        accuracy = accuracy_score(all_cls_labels, cls_pred_labels)\n",
    "        f1 = f1_score(all_cls_labels, cls_pred_labels)\n",
    "        try:\n",
    "            auc = roc_auc_score(all_cls_labels, all_cls_preds)\n",
    "        except Exception:\n",
    "            auc = float('nan')\n",
    "    if reg_loader:\n",
    "        all_reg_preds = torch.cat(all_reg_preds, dim=0).numpy().squeeze()\n",
    "        all_reg_labels = torch.cat(all_reg_labels, dim=0).numpy().squeeze()\n",
    "\n",
    "        mse = np.mean((all_reg_preds - all_reg_labels) ** 2)\n",
    "        mae = np.mean(np.abs(all_reg_preds - all_reg_labels))\n",
    "        ss_res = np.sum((all_reg_preds - all_reg_labels) ** 2)\n",
    "        ss_tot = np.sum((all_reg_labels - np.mean(all_reg_labels)) ** 2)\n",
    "        r2 = 1 - ss_res / ss_tot if ss_tot != 0 else float('nan')    \n",
    "    \n",
    "    return accuracy, f1, auc, mse, mae, r2, all_cls_preds, all_cls_labels, all_reg_preds, all_reg_labels\n",
    "\n",
    "accuracy, f1, auc, mse, mae, r2, all_cls_preds, all_cls_labels, all_reg_preds, all_reg_labels = validate_model(model, val_cls_loader, val_reg_loader, device)\n",
    "print(\"Validation Metrics:\")\n",
    "print(f\"Classification -> Accuracy: {accuracy:.4f}, F1: {f1:.4f}, AUC: {auc:.4f}\")\n",
    "print(f\"Regression     -> MSE: {mse:.4f}, MAE: {mae:.4f}, R²: {r2:.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Metrics:\n",
      "Classification -> Accuracy: 0.9672, F1: 0.9754, AUC: 0.9951\n",
      "Regression     -> MSE: 0.0026, MAE: 0.0393, R²: 0.8867\n"
     ]
    }
   ],
   "source": [
    "accuracy, f1, auc, mse, mae, r2, all_cls_preds, all_cls_labels, all_reg_preds, all_reg_labels = validate_model(model, test_cls_loader, test_reg_loader, device)\n",
    "print(\"Test Metrics:\")\n",
    "print(f\"Classification -> Accuracy: {accuracy:.4f}, F1: {f1:.4f}, AUC: {auc:.4f}\")\n",
    "print(f\"Regression     -> MSE: {mse:.4f}, MAE: {mae:.4f}, R²: {r2:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>peptide</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>AEAEAEAEAKAKAKAK</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>GGGGDD</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>GFFLGLDD</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>QEIARLEQEIARLEYEIARLE</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>NNQQNY</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>363</th>\n",
       "      <td>YTEYK</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>364</th>\n",
       "      <td>EPYYK</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>365</th>\n",
       "      <td>YDPKY</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>366</th>\n",
       "      <td>KDPYY</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>367</th>\n",
       "      <td>YEPYK</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>368 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                   peptide  label\n",
       "0         AEAEAEAEAKAKAKAK      1\n",
       "1                   GGGGDD      1\n",
       "2                 GFFLGLDD      1\n",
       "3    QEIARLEQEIARLEYEIARLE      1\n",
       "4                   NNQQNY      1\n",
       "..                     ...    ...\n",
       "363                  YTEYK      0\n",
       "364                  EPYYK      0\n",
       "365                  YDPKY      0\n",
       "366                  KDPYY      0\n",
       "367                  YEPYK      0\n",
       "\n",
       "[368 rows x 2 columns]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# load experimental data\n",
    "experimental_df = pd.read_csv(\"../../clean_data/experimental.csv\", keep_default_na=False, na_values=[''], sep=';')\n",
    "experimental_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>peptide</th>\n",
       "      <th>is_assembled</th>\n",
       "      <th>len</th>\n",
       "      <th>stratify_key</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>GGGGDD</td>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>GFFLGLDD</td>\n",
       "      <td>1</td>\n",
       "      <td>8</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>NNQQNY</td>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>AILSS</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>YVIFL</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>363</th>\n",
       "      <td>YTEYK</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>364</th>\n",
       "      <td>EPYYK</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>365</th>\n",
       "      <td>YDPKY</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>366</th>\n",
       "      <td>KDPYY</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>367</th>\n",
       "      <td>YEPYK</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>326 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      peptide  is_assembled  len stratify_key\n",
       "1      GGGGDD             1    6            6\n",
       "2    GFFLGLDD             1    8            8\n",
       "4      NNQQNY             1    6            6\n",
       "5       AILSS             1    5            5\n",
       "6       YVIFL             1    5            5\n",
       "..        ...           ...  ...          ...\n",
       "363     YTEYK             0    5            5\n",
       "364     EPYYK             0    5            5\n",
       "365     YDPKY             0    5            5\n",
       "366     KDPYY             0    5            5\n",
       "367     YEPYK             0    5            5\n",
       "\n",
       "[326 rows x 4 columns]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "experimental_df['len'] = experimental_df['peptide'].apply(len)\n",
    "experimental_df.rename(columns={'label': 'is_assembled'}, inplace=True)\n",
    "experimental_df['stratify_key'] = experimental_df['len'].apply(get_stratification_key)\n",
    "\n",
    "experimental_df = experimental_df[experimental_df['len'] <= max_seq_length - 2]\n",
    "experimental_dataset = PeptidePredictorDataset(experimental_df, task='classification')\n",
    "experimental_loader = DataLoader(experimental_dataset, batch_size=batch_size, shuffle=False, collate_fn=esm_collate_fn)\n",
    "experimental_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Experimental Data Metrics:\n",
      "Classification -> Accuracy: 0.5521, F1: 0.6033, AUC: 0.5601\n",
      "Regression     -> MSE: nan, MAE: nan, R²: nan\n"
     ]
    }
   ],
   "source": [
    "accuracy, f1, auc, mse, mae, r2, all_cls_preds, all_cls_labels, all_reg_preds, all_reg_labels = validate_model(model, experimental_loader, [], device)\n",
    "print(\"Experimental Data Metrics:\")\n",
    "print(f\"Classification -> Accuracy: {accuracy:.4f}, F1: {f1:.4f}, AUC: {auc:.4f}\")\n",
    "print(f\"Regression     -> MSE: {mse:.4f}, MAE: {mae:.4f}, R²: {r2:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_3979723/1336428635.py:2: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  experimental_df['predicted_is_assembled'] = all_cls_preds\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>peptide</th>\n",
       "      <th>is_assembled</th>\n",
       "      <th>predicted_is_assembled</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>GGGGDD</td>\n",
       "      <td>1</td>\n",
       "      <td>-2.919494</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>GFFLGLDD</td>\n",
       "      <td>1</td>\n",
       "      <td>2.590684</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>NNQQNY</td>\n",
       "      <td>1</td>\n",
       "      <td>-6.989876</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>AILSS</td>\n",
       "      <td>1</td>\n",
       "      <td>3.247889</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>YVIFL</td>\n",
       "      <td>1</td>\n",
       "      <td>12.237429</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>363</th>\n",
       "      <td>YTEYK</td>\n",
       "      <td>0</td>\n",
       "      <td>4.245285</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>364</th>\n",
       "      <td>EPYYK</td>\n",
       "      <td>0</td>\n",
       "      <td>3.144766</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>365</th>\n",
       "      <td>YDPKY</td>\n",
       "      <td>0</td>\n",
       "      <td>4.263178</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>366</th>\n",
       "      <td>KDPYY</td>\n",
       "      <td>0</td>\n",
       "      <td>4.366505</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>367</th>\n",
       "      <td>YEPYK</td>\n",
       "      <td>0</td>\n",
       "      <td>3.801728</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>326 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      peptide  is_assembled  predicted_is_assembled\n",
       "1      GGGGDD             1               -2.919494\n",
       "2    GFFLGLDD             1                2.590684\n",
       "4      NNQQNY             1               -6.989876\n",
       "5       AILSS             1                3.247889\n",
       "6       YVIFL             1               12.237429\n",
       "..        ...           ...                     ...\n",
       "363     YTEYK             0                4.245285\n",
       "364     EPYYK             0                3.144766\n",
       "365     YDPKY             0                4.263178\n",
       "366     KDPYY             0                4.366505\n",
       "367     YEPYK             0                3.801728\n",
       "\n",
       "[326 rows x 3 columns]"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# show df with predictions\n",
    "experimental_df['predicted_is_assembled'] = all_cls_preds\n",
    "\n",
    "experimental_df[['peptide', 'is_assembled', 'predicted_is_assembled']]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of common peptides in experimental and regression data: 9\n"
     ]
    }
   ],
   "source": [
    "# which peptides are in the experimental data and also classification_df?\n",
    "peptides_in_experimental = set(experimental_df['peptide'])\n",
    "peptides_in_regression = set(regression_df['peptide'])\n",
    "common_peptides = peptides_in_experimental.intersection(peptides_in_regression)\n",
    "print(f\"Number of common peptides in experimental and regression data: {len(common_peptides)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Common peptides in experimental and classification data:\n",
      "  peptide  is_assembled  predicted_is_assembled        ap\n",
      "0     DFY             1                0.180612  0.314015\n",
      "1    GFIL             1                0.999707  0.490410\n",
      "2     IID             1                0.005936  0.260011\n",
      "3     IVD             1                0.005513  0.172776\n",
      "4     KFG             1                0.200675  0.336357\n",
      "5     KYF             1                0.990598  0.609441\n",
      "6     LFF             1                0.999992  0.839569\n",
      "7  VQIVYK             1                0.983682  0.430783\n",
      "8   VVVVV             1                0.999842  0.591718\n"
     ]
    }
   ],
   "source": [
    "# for the common peptides, show the peptide, is_assembled from experiments, predicted is_assembled, and ap from classification_df\n",
    "common_peptides_df = regression_df[regression_df['peptide'].isin(common_peptides)]\n",
    "common_peptides_df = common_peptides_df[['peptide', 'ap']]\n",
    "common_peptides_df = common_peptides_df.merge(experimental_df[['peptide', 'is_assembled', 'predicted_is_assembled']], on='peptide')\n",
    "common_peptides_df = common_peptides_df[['peptide', 'is_assembled', 'predicted_is_assembled', 'ap']]\n",
    "print(\"Common peptides in experimental and classification data:\")\n",
    "print(common_peptides_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cmp_reg = pd.DataFrame(\n",
    "    {\"peptide\":['MWYWKF'], 'ap':[2.194], \"len\":[6], 'stratify_key':[6] }\n",
    ")\n",
    "cmp_dataset  = PeptidePredictorDataset(cmp_reg, task='regression')\n",
    "cmp_loader  = DataLoader(cmp_dataset, batch_size=1, shuffle=False, collate_fn=esm_collate_fn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 0, 20, 22, 19, 22, 15, 18,  2,  1,  1,  1,  1]], device='cuda:0') tensor([[0.5457]], device='cuda:0') tensor([[1.0000]], device='cuda:0')\n"
     ]
    }
   ],
   "source": [
    "with torch.no_grad():\n",
    "    for tokens, targets in cmp_loader:\n",
    "        tokens = tokens.to(device)\n",
    "        targets = targets.to(device)\n",
    "        ap_pred, clas_pred = model(tokens)\n",
    "        print(tokens, ap_pred, clas_pred)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
