{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, sys\n",
    "os.environ['CUDA_VISIBLE_DEVICES'] = '2,3'\n",
    "\n",
    "root = os.path.abspath(os.path.join(os.getcwd(), '..'))\n",
    "if root not in sys.path:\n",
    "    sys.path.insert(0, root)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda 2\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import pandas as pd\n",
    "from torch.utils.data import DataLoader\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from cvae.models import CVAESimpleEnc\n",
    "from cvae.datasets import CVAEAllDataset\n",
    "from cvae.utils import (\n",
    "    CONDITION_LENGTH, MAX_FASTA_LENGTH, MAX_SEQ_LENGTH, ALPHABET, PAD_TOKEN_ID,\n",
    "    finetune_collate_fn, vae_loss_fn_with_cond\n",
    ")\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(device, torch.cuda.device_count())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 2048\n",
    "df = pd.read_csv(\"../../clean_data/merged_all.csv\", keep_default_na=False, na_values=[''])\n",
    "train_val_df, test_df = train_test_split(df, test_size=0.1, stratify=df['length'], random_state=42)\n",
    "train_df, val_df = train_test_split(train_val_df, test_size=0.1, stratify=train_val_df['length'], random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "FEATURES = [\n",
    "    \"length\",\n",
    "    \"is_assembled\",\n",
    "    \"ap\",\n",
    "    \"has_beta_sheet_content\",\n",
    "    \"hydrophobic_moment\",\n",
    "    \"net_charge\",\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = CVAEAllDataset(train_df, max_fasta_length=MAX_FASTA_LENGTH, random_mask=True)\n",
    "val_dataset   = CVAEAllDataset(val_df, max_fasta_length=MAX_FASTA_LENGTH)\n",
    "test_dataset  = CVAEAllDataset(test_df, max_fasta_length=MAX_FASTA_LENGTH)\n",
    "\n",
    "train_loader_ft = DataLoader(train_dataset, batch_size=batch_size, shuffle=True, collate_fn=finetune_collate_fn)\n",
    "val_loader_ft   = DataLoader(val_dataset, batch_size=batch_size, shuffle=False, collate_fn=finetune_collate_fn)\n",
    "test_loader_ft  = DataLoader(test_dataset, batch_size=batch_size, shuffle=False, collate_fn=finetune_collate_fn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda 2\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(device, torch.cuda.device_count())\n",
    "\n",
    "cvae_model = CVAESimpleEnc(\n",
    "    encoder_hidden_dim=256,\n",
    "    num_encoder_layers=2,\n",
    "    vocab_size=len(ALPHABET),\n",
    "    latent_dim=24,\n",
    "    cond_dim=CONDITION_LENGTH,\n",
    "    max_seq_length=MAX_SEQ_LENGTH,\n",
    "    decoder_hidden_dim=256,\n",
    "    num_decoder_layers=2,\n",
    "    nhead=8,\n",
    "    dropout=0.1)\n",
    "\n",
    "pretrained_state_dict = torch.load(\"../cvae/chkpts/finetuned_cvae.pt\", map_location=device, weights_only=True)\n",
    "cvae_model.load_state_dict(pretrained_state_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using 2 GPUs\n",
      "CVAE initialized with finetuned architecture\n"
     ]
    }
   ],
   "source": [
    "cvae_model.eval()\n",
    "\n",
    "if torch.cuda.device_count() > 1:\n",
    "    print(f\"Using {torch.cuda.device_count()} GPUs\")\n",
    "    cvae_model = nn.DataParallel(cvae_model)\n",
    "\n",
    "cvae_model.to(device)\n",
    "print(\"CVAE initialized with finetuned architecture\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/go46vuw/miniconda3/lib/python3.12/site-packages/torch/nn/modules/transformer.py:508: UserWarning: The PyTorch API of nested tensors is in prototype stage and will change in the near future. We recommend specifying layout=torch.jagged when constructing a nested tensor, as this layout receives active development, has better operator coverage, and works with torch.compile. (Triggered internally at /home/conda/feedstock_root/build_artifacts/libtorch_1744233415586/work/aten/src/ATen/NestedTensorImpl.cpp:178.)\n",
      "  output = torch._nested_tensor_from_mask(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==== Validation metrics ====\n",
      "Loss: 1.3964 | Recon: 1.0401 | KL: 17.8119\n",
      "Perplexity: 2.83\n"
     ]
    }
   ],
   "source": [
    "def evaluate(model, dataloader, pad_idx, device, kl_weight, cond_weight):\n",
    "    model.eval()\n",
    "    total = {\n",
    "        \"loss\":    0.0,\n",
    "        \"recon\":   0.0,\n",
    "        \"kl\":      0.0,\n",
    "        \"mse\":     0.0,\n",
    "        \"tokens\":  0,\n",
    "    }\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for tokens, tgt_tokens, conds, mask in dataloader:\n",
    "            B = tokens.size(0)\n",
    "            tokens     = tokens.to(device)\n",
    "            tgt_tokens = tgt_tokens.to(device)\n",
    "            conds      = conds.to(device)\n",
    "            mask       = mask.to(device)\n",
    "\n",
    "            logits, mu, logvar, prior_mu, prior_logvar, bc_logit, cc_pred, mask_logit = \\\n",
    "                model(tokens, conds, mask)\n",
    "\n",
    "            #vocab_size = logits.size(-1)\n",
    "\n",
    "            loss, recon, kl, _ = vae_loss_fn_with_cond(\n",
    "                logits=logits.view(-1, logits.size(-1)),\n",
    "                tgt=tgt_tokens.view(-1),\n",
    "                mu=mu, logvar=logvar, prior_mu=prior_mu, prior_logvar=prior_logvar,\n",
    "                bc_logit=bc_logit, cc_pred=cc_pred, mask_logit=mask_logit,\n",
    "                cond=conds, mask=mask,\n",
    "                pad_idx=PAD_TOKEN_ID, kl_weight=kl_weight, lambda_bin=1.0, lambda_cont=1.0\n",
    "            )\n",
    "\n",
    "            total[\"loss\"]  += loss.item() * B\n",
    "            total[\"recon\"] += recon.item() * B\n",
    "            total[\"kl\"]    += kl.item() * B\n",
    "            total[\"tokens\"] += (tgt_tokens != pad_idx).sum().item()\n",
    "\n",
    "    N = len(dataloader.dataset)\n",
    "    total[\"loss\"]  /= N\n",
    "    total[\"recon\"] /= N\n",
    "    total[\"kl\"]    /= N\n",
    "\n",
    "    total[\"ppl\"] = float(torch.exp(torch.tensor(total[\"recon\"] * total[\"tokens\"] / total[\"tokens\"])))\n",
    "\n",
    "    return total\n",
    "\n",
    "\n",
    "metrics = evaluate(\n",
    "    model=cvae_model,\n",
    "    dataloader=val_loader_ft,\n",
    "    pad_idx=PAD_TOKEN_ID,\n",
    "    device=device,\n",
    "    kl_weight=0.02,\n",
    "    cond_weight=50.0\n",
    ")\n",
    "\n",
    "print(\"==== Validation metrics ====\")\n",
    "print(f\"Loss: {metrics['loss']:.4f} | Recon: {metrics['recon']:.4f} | KL: {metrics['kl']:.4f}\")\n",
    "print(f\"Perplexity: {metrics['ppl']:.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==== Test metrics ====\n",
      "Loss: 1.3926 | Recon: 1.0351 | KL: 17.8712\n",
      "Perplexity: 2.82\n"
     ]
    }
   ],
   "source": [
    "metrics = evaluate(\n",
    "    model=cvae_model,\n",
    "    dataloader=test_loader_ft,\n",
    "    pad_idx=PAD_TOKEN_ID,\n",
    "    device=device,\n",
    "    kl_weight=0.02,\n",
    "    cond_weight=50.0\n",
    ")\n",
    "\n",
    "print(\"==== Test metrics ====\")\n",
    "print(f\"Loss: {metrics['loss']:.4f} | Recon: {metrics['recon']:.4f} | KL: {metrics['kl']:.4f}\")\n",
    "print(f\"Perplexity: {metrics['ppl']:.2f}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
